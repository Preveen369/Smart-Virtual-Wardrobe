{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6305618,"sourceType":"datasetVersion","datasetId":3627552}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-20T07:25:33.434831Z","iopub.execute_input":"2023-09-20T07:25:33.43539Z","iopub.status.idle":"2023-09-20T07:26:03.056388Z","shell.execute_reply.started":"2023-09-20T07:25:33.435355Z","shell.execute_reply":"2023-09-20T07:26:03.055333Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import utils,layers,Sequential\nimport tensorflow_hub as hub","metadata":{"execution":{"iopub.status.busy":"2025-07-14T13:13:34.362830Z","iopub.execute_input":"2025-07-14T13:13:34.363102Z","iopub.status.idle":"2025-07-14T13:13:34.368171Z","shell.execute_reply.started":"2025-07-14T13:13:34.363079Z","shell.execute_reply":"2025-07-14T13:13:34.367196Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"train = utils.image_dataset_from_directory('/kaggle/input/virtual-tryon-dataset/Virtual tryon data/train',image_size=(256,256),seed=42)\ntest = utils.image_dataset_from_directory('/kaggle/input/virtual-tryon-dataset/Virtual tryon data/train',image_size=(256,256),seed=42)\n\n#normalize the data\ndef process(image,label):\n    image = tf.cast(image/255. ,tf.float32)\n    return image,label\n\ntrain = train.map(process)\ntest = test.map(process)","metadata":{"execution":{"iopub.status.busy":"2025-07-14T13:13:37.993927Z","iopub.execute_input":"2025-07-14T13:13:37.994495Z","iopub.status.idle":"2025-07-14T13:15:03.066043Z","shell.execute_reply.started":"2025-07-14T13:13:37.994440Z","shell.execute_reply":"2025-07-14T13:15:03.065482Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Found 46588 files belonging to 5 classes.\nFound 46588 files belonging to 5 classes.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"model = Sequential([\n    layers.Input(shape=(256,256,3)),\n    hub.KerasLayer('https://tfhub.dev/tensorflow/efficientnet/b7/classification/1'),\n    #the layer which loads eff_net b7\n    layers.Dense(128,activation=\"relu\"),\n    layers.Dense(64,activation='relu'),\n    layers.Dense(4,activation='softmax')\n])\n","metadata":{"execution":{"iopub.status.busy":"2025-07-14T13:15:03.067278Z","iopub.execute_input":"2025-07-14T13:15:03.067525Z","iopub.status.idle":"2025-07-14T13:15:32.260874Z","shell.execute_reply.started":"2025-07-14T13:15:03.067504Z","shell.execute_reply":"2025-07-14T13:15:32.260138Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2025-07-14T13:17:22.068771Z","iopub.execute_input":"2025-07-14T13:17:22.069477Z","iopub.status.idle":"2025-07-14T13:17:22.104203Z","shell.execute_reply.started":"2025-07-14T13:17:22.069434Z","shell.execute_reply":"2025-07-14T13:17:22.103382Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n keras_layer (KerasLayer)    (None, 1000)              66658680  \n                                                                 \n dense (Dense)               (None, 128)               128128    \n                                                                 \n dense_1 (Dense)             (None, 64)                8256      \n                                                                 \n dense_2 (Dense)             (None, 4)                 260       \n                                                                 \n=================================================================\nTotal params: 66,795,324\nTrainable params: 136,644\nNon-trainable params: 66,658,680\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"model.compile(\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.015),\n    metrics=['Accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-07-14T13:17:26.118283Z","iopub.execute_input":"2025-07-14T13:17:26.119105Z","iopub.status.idle":"2025-07-14T13:17:26.136326Z","shell.execute_reply.started":"2025-07-14T13:17:26.119076Z","shell.execute_reply":"2025-07-14T13:17:26.135500Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"earlystopping=tf.keras.callbacks.EarlyStopping(\n    monitor='Accuracy',\n    min_delta=0.0001,\n    patience=2,\n    restore_best_weights=True,\n    start_from_epoch=1\n)\n\ntensorboard= tf.keras.callbacks.TensorBoard()\nchkpt = tf.keras.callbacks.ModelCheckpoint(\n    'mango.ckpt',\n    monitor = 'Accuracy',\n    save_best_only = True,\n    mode = 'auto',\n    save_freq='epoch',\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-07-14T13:17:33.233843Z","iopub.execute_input":"2025-07-14T13:17:33.234152Z","iopub.status.idle":"2025-07-14T13:17:33.239089Z","shell.execute_reply.started":"2025-07-14T13:17:33.234126Z","shell.execute_reply":"2025-07-14T13:17:33.238272Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"with tf.device('/GPU:0'):\n    model.fit(train,\n              epochs=4,\n              callbacks=[earlystopping,tensorboard,chkpt])","metadata":{"execution":{"iopub.status.busy":"2025-07-14T13:17:37.313137Z","iopub.execute_input":"2025-07-14T13:17:37.313896Z","iopub.status.idle":"2025-07-14T14:01:00.532659Z","shell.execute_reply.started":"2025-07-14T13:17:37.313867Z","shell.execute_reply":"2025-07-14T14:01:00.531972Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/4\n1456/1456 [==============================] - 711s 466ms/step - loss: 0.1367 - Accuracy: 0.9545\nEpoch 2/4\n1456/1456 [==============================] - 631s 433ms/step - loss: 0.0515 - Accuracy: 0.9827\nEpoch 3/4\n1456/1456 [==============================] - 631s 433ms/step - loss: 0.0406 - Accuracy: 0.9864\nEpoch 4/4\n1456/1456 [==============================] - 631s 433ms/step - loss: 0.0336 - Accuracy: 0.9890\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model.save(\"/kaggle/working/my_model_virtual_tryon.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T14:02:57.835070Z","iopub.execute_input":"2025-07-14T14:02:57.835403Z","iopub.status.idle":"2025-07-14T14:02:58.817742Z","shell.execute_reply.started":"2025-07-14T14:02:57.835376Z","shell.execute_reply":"2025-07-14T14:02:58.817043Z"}},"outputs":[],"execution_count":8}]}